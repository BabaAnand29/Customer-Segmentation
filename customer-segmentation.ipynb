import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from io import StringIO

# For interactive plotly scatter (optional)
import plotly.express as px

# Embedded Mall Customer dataset CSV as a string (first 50 rows for demo)
csv_data = """
CustomerID,Gender,Age,Annual Income (k$),Spending Score (1-100)
1,Male,19,15,39
2,Male,21,15,81
3,Female,20,16,6
4,Female,23,16,77
5,Female,31,17,40
6,Female,22,17,76
7,Female,35,18,6
8,Female,23,18,94
9,Male,64,19,3
10,Female,30,19,72
11,Male,67,19,14
12,Female,35,19,99
13,Female,58,20,15
14,Female,24,20,77
15,Male,37,20,13
16,Male,22,20,79
17,Female,35,21,35
18,Male,20,21,66
19,Female,52,23,29
20,Female,35,23,98
21,Male,35,24,35
22,Male,25,24,73
23,Female,46,25,5
24,Male,31,25,73
25,Female,54,28,14
26,Female,29,28,82
27,Male,45,28,32
28,Female,35,28,61
29,Male,40,29,31
30,Female,23,29,87
31,Male,60,30,4
32,Female,21,30,73
33,Female,53,33,4
34,Male,18,33,92
35,Female,49,33,14
36,Female,21,33,81
37,Male,42,34,17
38,Female,30,34,73
39,Female,36,37,26
40,Female,20,37,75
41,Male,65,38,35
42,Female,24,38,92
43,Male,48,39,36
44,Male,31,39,61
45,Female,49,39,28
46,Male,24,39,65
47,Female,50,40,55
48,Female,27,40,47
49,Male,29,40,42
50,Female,31,40,42
"""

# Load dataset from the embedded CSV string
df = pd.read_csv(StringIO(csv_data))

# Show first 5 rows
print("First 5 rows of dataset:")
print(df.head())

# Select features for clustering
X = df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Use Elbow method to find optimal number of clusters
inertia = []
k_range = range(1, 11)
for k in k_range:
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(X_scaled)
    inertia.append(km.inertia_)

# Plot the elbow curve
plt.figure(figsize=(8, 4))
plt.plot(k_range, inertia, marker='o')
plt.title('Elbow Method For Optimal k')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.grid(True)
plt.show()

# Based on elbow plot, choose k=4 or 5 (for example k=4)
k = 4
kmeans = KMeans(n_clusters=k, random_state=42)
clusters = kmeans.fit_predict(X_scaled)
df['Cluster'] = clusters

# Cluster counts bar plot
plt.figure(figsize=(6,4))
sns.countplot(x='Cluster', data=df, palette='Set1')
plt.title('Count of Customers in Each Cluster')
plt.xlabel('Cluster')
plt.ylabel('Count')
plt.show()

# Visualize clusters with centers
plt.figure(figsize=(8, 6))
sns.scatterplot(data=df, x='Annual Income (k$)', y='Spending Score (1-100)',
                hue='Cluster', palette='Set1', s=100, alpha=0.7)
centers = scaler.inverse_transform(kmeans.cluster_centers_)
plt.scatter(centers[:, 1], centers[:, 2], c='black', s=200, marker='X', label='Centroids')
plt.title('Customer Segmentation (K-Means Clustering)')
plt.legend(title='Cluster')
plt.grid(True)
plt.show()

# Pairplot colored by cluster for deeper insight
sns.pairplot(df, vars=['Age', 'Annual Income (k$)', 'Spending Score (1-100)'], hue='Cluster', palette='Set1')
plt.suptitle('Pairplot of Features Colored by Cluster', y=1.02)
plt.show()

# Optional: Interactive scatter plot with plotly
fig = px.scatter(df, x='Annual Income (k$)', y='Spending Score (1-100)', color='Cluster',
                 hover_data=['Age', 'CustomerID'], title='Interactive Customer Segmentation')
fig.show()

# Print cluster centers (inverse transform to original scale)
centers_df = pd.DataFrame(centers, columns=['Age', 'Annual Income (k$)', 'Spending Score (1-100)'])
print("\nCluster Centers:")
print(centers_df)
